{"cells":[{"metadata":{"_uuid":"0a5dd1bb4db47e3313cc9957857eb3f4684dd11f"},"cell_type":"markdown","source":"## Data Preparation\nTo begin this exploratory analysis, first use `matplotlib` to import libraries and define functions for plotting the data."},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nimport os\nimport shutil\n# from keras.applications.inception_v3 import InceptionV3\n# from keras.applications.inception_v3 import preprocess_input, decode_predictions\n# from keras.applications.resnet import ResNet152\n# from keras.applications.resnet import preprocess_input, decode_predictions\nfrom keras.applications.nasnet import NASNetLarge\nfrom keras.applications.nasnet import preprocess_input, decode_predictions\n# from keras.applications.inception_resnet_v2 import InceptionResNetV2\n# from keras.applications.inception_resnet_v2 import preprocess_input, decode_predictions\n# from keras.applications.xception import Xception\n# from keras.applications.xception import preprocess_input, decode_predictions\nfrom keras.models import Model\nfrom keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array, array_to_img\nfrom collections import Counter\nfrom keras.layers import Conv2D, GlobalAveragePooling2D, MaxPooling2D, Flatten, Dense, Dropout, InputLayer\nfrom keras.models import Sequential\nfrom keras import optimizers\nfrom sklearn.preprocessing import LabelEncoder \nfrom keras.utils import to_categorical\nimport math","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_val = [0, .1, .2]\nxception_article = [66.38, 75.56, 80.96]\nInceptionV3_article = [61.81, 71.85, 78.15]\nResnet50_article = [67.84, 76.73, 82.21]\nResnet50v2_article = [66.78, 76.17, 81.97]\nResnet152_article = [ 68.66, 77.44, 82.99]\nInceptionResnet_article = [ 62.78, 71.93, 78.27]\nNasnetLarge_article = [ 68.48, 77.40, 82.71]\n\n\nxception_gender = [ 56.40, 68.27, 75.98]\nInceptionV3_gender = [ 53.77, 66.62, 75.04]\nResnet50_gender = [63.67, 74.24, 81.02]\nResnet50v2_gender = [ 60.26, 71.74, 79.32]\nResnet152_gender = [ 63.94, 74.75, 81.39]\nInceptionResnet_gender = [ 53.68, 65.49, 73.73]\nNasnetLarge_gender = [ 54.14, 66.86, 75.81]\n\n\nxception_gender_article = [ 42.41, 54.46, 63.16]\nInceptionV3_gender_article = [ 38.41, 51.04, 60.23]\nResnet50_gender_article = [ 47.03, 58.92, 67.50 ]\nResnet50v2_gender_article = [ 44.00, 56.42, 65.50]\nResnet152_gender_article = [ 47.80, 59.98, 68.48]\nInceptionResnet_gender_article = [ 38.61, 49.99, 59.01]\nNasnetLarge_gender_article = [ 43.75, 56.12, 64.91]\n\n\n\nplt.figure(figsize=(21, 24))\nplt.subplot(3, 1, 1)\nplt.plot(x_val, xception_article, label='Xception')\nplt.plot(x_val,InceptionV3_article, label='InceptionV3')\nplt.plot(x_val,Resnet50_article, label='Resnet50')\nplt.plot(x_val,Resnet50v2_article, label='Resnet50v2')\nplt.plot(x_val,Resnet152_article, label='Resnet152')\nplt.plot(x_val,InceptionResnet_article, label='InceptionResnet')\nplt.plot(x_val,NasnetLarge_article, label='NasnetLarge')\n\nplt.legend(loc='lower right')\nplt.ylabel('Precision')\nplt.title('Precision for article type')\n\nplt.subplot(3, 1, 2)\nplt.plot(x_val, xception_gender, label='Xception')\nplt.plot(x_val, InceptionV3_gender, label='InceptionV3')\nplt.plot(x_val, Resnet50_gender, label='Resnet50')\nplt.plot(x_val, Resnet50v2_gender, label='Resnet50v2')\nplt.plot(x_val, Resnet152_gender, label='Resnet152')\nplt.plot(x_val, InceptionResnet_gender, label='InceptionResnet')\nplt.plot(x_val, NasnetLarge_gender, label='NasnetLarge')\n\nplt.legend(loc='lower right')\nplt.ylabel('Precision')\nplt.title('Precision for gender')\n\n\nplt.subplot(3, 1, 3)\nplt.plot(x_val,xception_gender_article, label='Xception')\nplt.plot(x_val,InceptionV3_gender_article, label='InceptionV3')\nplt.plot(x_val,Resnet50_gender_article, label='Resnet50')\nplt.plot(x_val,Resnet50v2_gender_article, label='Resnet50v2')\nplt.plot(x_val,Resnet152_gender_article, label='Resnet152')\nplt.plot(x_val,InceptionResnet_gender_article, label='InceptionResnet')\nplt.plot(x_val,NasnetLarge_gender_article, label='NasnetLarge')\n\nplt.legend(loc='lower right')\nplt.ylabel('Precision')\nplt.title('Precision for gender and article type')\nplt.xlabel('Tolerance')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":false,"_uuid":"7c96d605282a65cebf83737bbf0a3386c5c3f19e","trusted":true},"cell_type":"code","source":"DATASET_PATH = \"/kaggle/input/fashion-product-images-dataset/fashion-dataset/fashion-dataset/\"\nprint(os.listdir(DATASET_PATH))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f92cc76567188bdfe9dfa0d720d163f2702ab4fb","trusted":true},"cell_type":"code","source":"# df = pd.read_csv(DATASET_PATH + \"styles.csv\", nrows=1000, error_bad_lines=False)\ndf = pd.read_csv(DATASET_PATH + \"styles.csv\", error_bad_lines=False)\n# df = df.groupby('articleType').filter(lambda x: len(x) >= 650);\n# df = df.groupby('articleType').head(11)\n# delete_row = df[df[\"id\"]==39403].index\n# df = df.drop(delete_row)\n# delete_row = df[df[\"id\"]==12347].index\n# df = df.drop(delete_row)\n# delete_row = df[df[\"id\"]==39410].index\n# df = df.drop(delete_row)\n# delete_row = df[df[\"id\"]==39425].index\n# df = df.drop(delete_row)\n# delete_row = df[df[\"id\"]==39401].index\n# df = df.drop(delete_row)\ndf['image'] = df.apply(lambda row: str(row['id']) + \".jpg\", axis=1)\ndf = df.reset_index(drop=True)\ndf.head(10)\ndf.articleType.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[df[\"id\"]==12347]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import cv2\ndef plot_figures(figures, nrows = 1, ncols=1,figsize=(5, 5)):\n    \"\"\"Plot a dictionary of figures.\n\n    Parameters\n    ----------\n    figures : <title, figure> dictionary\n    ncols : number of columns of subplots wanted in the display\n    nrows : number of rows of subplots wanted in the figure\n    \"\"\"\n\n    fig, axeslist = plt.subplots(ncols=ncols, nrows=nrows,figsize=figsize)\n    for ind,title in enumerate(figures):\n        axeslist.ravel()[ind].imshow(cv2.cvtColor(figures[title], cv2.COLOR_BGR2RGB))\n        axeslist.ravel()[ind].set_title(title)\n        axeslist.ravel()[ind].set_axis_off()\n    plt.tight_layout() # optional\n    \ndef img_path(img):\n    return DATASET_PATH+\"images/\"+img\n\ndef load_image(img, resized_fac = 1):\n    img     = cv2.imread(img_path(img))\n    w, h, _ = img.shape\n    resized = cv2.resize(img, (int(h*resized_fac), int(w*resized_fac)), interpolation = cv2.INTER_AREA)\n    return resized","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport numpy as np\n\n# generation of a dictionary of (title, images)\nfigures = {'im'+str(i): load_image(row.image) for i, row in df.sample(6).iterrows()}\n# plot of the images in a figure, with 2 rows and 3 columns\nplot_figures(figures, 2, 3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The Dataset is made up of different items that can be found in a marketplace. The idea is to use embeddings to search for similarity and find similar items just using the image."},{"metadata":{},"cell_type":"markdown","source":"## Use Pre-Trained Model to Recommendation"},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow as tf\nimport keras\nfrom keras import Model\nfrom keras.preprocessing import image\nfrom keras.layers import GlobalMaxPooling2D\ntf.__version__","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# # detect and init the TPU\n# tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n# tf.config.experimental_connect_to_cluster(tpu)\n# tf.tpu.experimental.initialize_tpu_system(tpu)\n\n# # instantiate a distribution strategy\n# tpu_strategy = tf.distribute.experimental.TPUStrategy(tpu)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Input Shape\nimg_width, img_height, _ = 331, 331, 3 #load_image(df.iloc[0].image).shape\n\n# Pre-Trained Model\nbase_model = NASNetLarge(weights='imagenet', \n                      include_top=False, \n                      input_shape = (img_width, img_height, 3))\nbase_model.trainable = False\n\n# Add Layer Embedding\nmodel = keras.Sequential([\n    base_model,\n    GlobalMaxPooling2D()\n])\n\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"i=0;\ndef get_embedding(model, img_name):\n    # Reshape\n#     if os.path.exists(img_path(img_name)):\n        img = image.load_img(img_path(img_name), target_size=(img_width, img_height))\n        # img to Array\n        x   = image.img_to_array(img)\n        # Expand Dim (1, w, h)\n        x   = np.expand_dims(x, axis=0)\n        # Pre process Input\n        x   = preprocess_input(x)\n        global i\n        i=i+1\n        print(i)\n        return model.predict(x).reshape(-1)\n#     else:\n#         return []","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Get item Embedding"},{"metadata":{"trusted":true},"cell_type":"code","source":"emb = get_embedding(model, df.iloc[0].image)\nemb.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"img_array = load_image(df.iloc[1].image)\nplt.imshow(cv2.cvtColor(img_array, cv2.COLOR_BGR2RGB))\nprint(img_array.shape)\nprint(emb)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Get Embedding for all itens in dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n#import swifter\n\n# Parallel apply\ndf_sample      = df#.sample(10)\nmap_embeddings = df_sample['image'].apply(lambda img: get_embedding(model, img))\ndf_embs        = map_embeddings.apply(pd.Series)\n\nprint(df_embs.shape)\ndf_embs.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Compute Similarity Between Items"},{"metadata":{"trusted":true},"cell_type":"code","source":"# https://scikit-learn.org/stable/modules/generated/sklearn.metrics.pairwise_distances.html\nimport time\nfrom sklearn.metrics.pairwise import pairwise_distances\nstart_time = time.time();\n\n# Calcule DIstance Matrix\n# reduce_mem_usage(df_embs)\ncosine_sim = 1-pairwise_distances(df_embs, metric='cosine')\ncosine_sim[:4, :4]\nend_time = time.time();\nspent_time = end_time - start_time;\nprint(spent_time)\n# reduce_mem_usage(cosine_sim )","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Recommender Similar Items"},{"metadata":{"trusted":true},"cell_type":"code","source":"indices = pd.Series(range(len(df_embs)), index=df_embs.index)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from scipy.spatial.distance import cosine\n# Function that get movie recommendations based on the cosine similarity score of movie genres\ndef get_recommender(idx, df, options, top_n = 5):\n    sim_idx    = indices[idx]\n    \n    filteredIndices = set();\n    \n    if len(options) > 0:\n        it = 0\n        for column in options:\n            if it == 0:\n                filteredIndices = set(df.index[df[column]== options[column]].tolist())\n            else:\n                filteredIndices = filteredIndices & set(df.index[df[column]== options[column]].tolist())\n            it = it + 1\n            \n        filteredIndices = list(filteredIndices)\n#         print(len(filteredIndices) )\n    else:\n        filteredIndices = list(indices.index)\n#     sim_scores =[];\n#     for i in range(len(df_embs)):\n#         sim_scores[i] = 1-cdist(df_embs[df_embs.index == sim_idx],df_embs[i], metric='cosine')\n    cosine_sim = [ 1 - cosine(df_embs.iloc[sim_idx], df_embs.iloc[i]) for i in range(len(df_embs))]\n    sim_scores = list(enumerate(cosine_sim))\n    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n    sim_scores = sim_scores[1: ]\n    \n    idx_rec = []\n    idx_sim = []\n    count_sim = 0\n    \n    for i in sim_scores:\n        if i[0] in filteredIndices:\n            idx_rec.append(i[0])\n            idx_sim.append(i[1])\n            count_sim = count_sim + 1\n            \n            if count_sim >= top_n:\n                break\n            \n    \n    idx_rec = indices.iloc[idx_rec].index\n    plt.imshow(cv2.cvtColor(load_image(df.iloc[idx].image), cv2.COLOR_BGR2RGB))\n    \n    \n    if(len(idx_rec) <= 0):\n        print('No matching item found for', options)\n    \n    plot_row = math.ceil(len(idx_sim)/3)\n    plot_col = min(3, len(idx_sim))\n        # Plot\n        #===================\n        # generation of a dictionary of (title, images)\n    figures = {'im'+str(i): load_image(row.image) for i, row in df.loc[idx_rec].iterrows()}\n        # plot of the images in a figure, with 2 rows and 3 columns\n    if len(figures):\n        plot_figures(figures, plot_row, plot_col)\n#     return idx_rec","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import time\ndef get_recommender_for_precision(idx, df, options, top_n = 5):\n    start_time = time.time();\n    sim_idx    = indices[idx]\n    \n    filteredIndices = set();\n    \n    if len(options) > 0:\n        it = 0\n        for column in options:\n            if it == 0:\n                filteredIndices = set(df.index[df[column]== options[column]].tolist())\n            else:\n                filteredIndices = filteredIndices & set(df.index[df[column]== options[column]].tolist())\n            it = it + 1\n            \n        filteredIndices = list(filteredIndices)\n#         print(len(filteredIndices) )\n    else:\n        filteredIndices = list(indices.index)\n#     sim_scores =[];\n#     for i in range(len(df_embs)):\n#         sim_scores[i] = 1-cdist(df_embs[df_embs.index == sim_idx],df_embs[i], metric='cosine')\n#     cosine_sim = [ 1 - cosine(df_embs.iloc[sim_idx], df_embs.iloc[i]) for i in range(len(df_embs))]\n#     sim_scores = list(enumerate(cosine_sim))\n    sim_scores = list(enumerate(cosine_sim[sim_idx]))\n    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n    sim_scores = sim_scores[1: ]\n    \n    idx_rec = []\n    idx_sim = []\n    count_sim = 0\n    \n    for i in sim_scores:\n        if i[0] in filteredIndices:\n            idx_rec.append(i[0])\n            idx_sim.append(i[1])\n            count_sim = count_sim + 1\n            \n            if count_sim >= top_n:\n                break\n            \n    \n    idx_rec = indices.iloc[idx_rec].index\n#     plt.imshow(cv2.cvtColor(load_image(df.iloc[idx].image), cv2.COLOR_BGR2RGB))\n    \n    \n    if(len(idx_rec) <= 0):\n        print('No matching item found for', options)\n    \n#     plot_row = math.ceil(len(idx_sim)/3)\n#     plot_col = min(3, len(idx_sim))\n#         # Plot\n#         #===================\n#         # generation of a dictionary of (title, images)\n#     figures = {'im'+str(i): load_image(row.image) for i, row in df.loc[idx_rec].iterrows()}\n#         # plot of the images in a figure, with 2 rows and 3 columns\n#     if len(figures):\n#         plot_figures(figures, plot_row, plot_col)\n    end_time = time.time();\n    return idx_rec","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# time_needed,id_rec = get_recommender_for_precision(7,df,{},10)\n# print(time_needed)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# precision = tp/tp+fp\ndef get_precision(df,top_n =10,tolarence=.8):\n    tp = len(df);\n    for i in range(len(df)):\n#         if i == 12347 or i == 39401 or i == 39403 or i == 39410 or i == 39425:\n#             continue;\n        id_rec= get_recommender_for_precision(i, df, {}, top_n);\n        c=0;\n        for j in range(len(id_rec)): \n            if df.iloc[i].gender == df.iloc[id_rec[j]].gender: # and df.iloc[i].articleType == df.iloc[id_rec[j]].articleType\n                c=c+1;\n        success_rate = c/top_n;\n        if success_rate < tolarence:\n            tp = tp -1;\n    return tp/len(df);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.iloc[1].gender","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Precision Calculation "},{"metadata":{"trusted":true},"cell_type":"code","source":"prec = get_precision(df,10,1)\nprint(prec)\ndf.iloc[1].articleType","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"base_color_filter = df['baseColour']=='Green'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(df_embs)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.iloc[19572].gender ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Idx Item to Recommender\nidx_ref = 7831\n\n# Recommendations\nget_recommender(idx_ref, df, { }, top_n = 6)\n# get_recommender(idx_ref, df, { \"gender\":df.iloc[idx_ref].gender }, top_n = 6)\n# get_recommender(idx_ref, df, { \"articleType\":df.iloc[idx_ref].articleType }, top_n = 6)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[df.index == 22]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[df.subCategory == 'Shoe'][df.baseColour == 'Black']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Search for items similar to the reference to recommend. Apparently it's working!**"},{"metadata":{"trusted":true},"cell_type":"code","source":"idx_ref = 8921\n\n# Recommendations\nidx_rec, idx_sim = get_recommender(idx_ref, df, {}, top_n = 6)\n\n# Plot\n#===================\nplt.imshow(cv2.cvtColor(load_image(df.iloc[idx_ref].image), cv2.COLOR_BGR2RGB))\n\n# generation of a dictionary of (title, images)\nfigures = {'im'+str(i): load_image(row.image) for i, row in df.loc[idx_rec].iterrows()}\n# plot of the images in a figure, with 2 rows and 3 columns\nplot_figures(figures, 2, 3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"idx_ref = 987\n\n# Recommendations\nidx_rec, idx_sim = get_recommender(idx_ref, df, {}, top_n = 6)\n\n# Plot\n#===================\nplt.imshow(cv2.cvtColor(load_image(df.iloc[idx_ref].image), cv2.COLOR_BGR2RGB))\n\n# generation of a dictionary of (title, images)\nfigures = {'im'+str(i): load_image(row.image) for i, row in df.loc[idx_rec].iterrows()}\n# plot of the images in a figure, with 2 rows and 3 columns\nplot_figures(figures, 2, 3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"idx_ref = 3524\n\n# Recommendations\nidx_rec, idx_sim = get_recommender(idx_ref, df, {}, top_n = 6)\n\n# Plot\n#===================\nplt.imshow(cv2.cvtColor(load_image(df.iloc[idx_ref].image), cv2.COLOR_BGR2RGB))\n\n# generation of a dictionary of (title, images)\nfigures = {'im'+str(i): load_image(row.image) for i, row in df.loc[idx_rec].iterrows()}\n# plot of the images in a figure, with 2 rows and 3 columns\nplot_figures(figures, 2, 3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# precision = tp/tp+fp\ndef get_precision(df,top_n =10):\n    tp = len(df);\n    for i in range(len(df)):\n        id_rec= get_recommender(i, df, {}, top_n);\n        for j in range(len(id_rec)):\n            if df.iloc[i].articleType != df.iloc[id_rec[j]].articleType :\n                tp = tp -1;\n                break;\n    return tp/len(df);","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4"}},"nbformat":4,"nbformat_minor":4}