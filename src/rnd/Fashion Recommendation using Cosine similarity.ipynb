{"cells":[{"metadata":{"_uuid":"0a5dd1bb4db47e3313cc9957857eb3f4684dd11f"},"cell_type":"markdown","source":"## Data Preparation\nTo begin this exploratory analysis, first use `matplotlib` to import libraries and define functions for plotting the data."},{"metadata":{"_kg_hide-input":false,"_uuid":"875b42ec5baee5274279d8a7b7a72159f3a586de","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nimport os\nimport shutil\nfrom keras.applications.inception_v3 import InceptionV3\nfrom keras.applications.inception_v3 import preprocess_input, decode_predictions\n# from keras.applications.resnet import ResNet152\n# from keras.applications.resnet import preprocess_input, decode_predictions\n# from keras.applications.nasnet import NASNetLarge\n# from keras.applications.nasnet import preprocess_input, decode_predictions\n# from keras.applications.inception_resnet_v2 import InceptionResNetV2\n# from keras.applications.inception_resnet_v2 import preprocess_input, decode_predictions\n# from keras.applications.xception import Xception\n# from keras.applications.xception import preprocess_input, decode_predictions\nfrom keras.models import Model\nfrom keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array, array_to_img\nfrom collections import Counter\nfrom keras.layers import Conv2D, GlobalAveragePooling2D, MaxPooling2D, Flatten, Dense, Dropout, InputLayer\nfrom keras.models import Sequential\nfrom keras import optimizers\nfrom sklearn.preprocessing import LabelEncoder \nfrom keras.utils import to_categorical\nimport math","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def reduce_mem_usage(df, verbose=True):\n    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n    start_mem = df.memory_usage().sum() / 1024**2\n    for col in df.columns:\n        col_type = df[col].dtypes\n        if col_type in numerics:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)\n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)\n\n    end_mem = df.memory_usage().sum() / 1024**2\n    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n\n    return df","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":false,"_uuid":"7c96d605282a65cebf83737bbf0a3386c5c3f19e","trusted":true},"cell_type":"code","source":"DATASET_PATH = \"/kaggle/input/fashion-product-images-dataset/fashion-dataset/fashion-dataset/\"\nprint(os.listdir(DATASET_PATH))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f92cc76567188bdfe9dfa0d720d163f2702ab4fb","trusted":true},"cell_type":"code","source":"# df = pd.read_csv(DATASET_PATH + \"styles.csv\", nrows=20000, error_bad_lines=False)\ndf = pd.read_csv(DATASET_PATH + \"styles.csv\", error_bad_lines=False)\ndf['image'] = df.apply(lambda row: str(row['id']) + \".jpg\", axis=1)\ndf = df.reset_index(drop=True)\ndf.head(10)\nreduce_mem_usage(df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import cv2\ndef plot_figures(figures, nrows = 1, ncols=1,figsize=(5, 5)):\n    \"\"\"Plot a dictionary of figures.\n\n    Parameters\n    ----------\n    figures : <title, figure> dictionary\n    ncols : number of columns of subplots wanted in the display\n    nrows : number of rows of subplots wanted in the figure\n    \"\"\"\n\n    fig, axeslist = plt.subplots(ncols=ncols, nrows=nrows,figsize=figsize)\n    for ind,title in enumerate(figures):\n        axeslist.ravel()[ind].imshow(cv2.cvtColor(figures[title], cv2.COLOR_BGR2RGB))\n        axeslist.ravel()[ind].set_title(title)\n        axeslist.ravel()[ind].set_axis_off()\n    plt.tight_layout() # optional\n    \ndef img_path(img):\n    return DATASET_PATH+\"images/\"+img\n\ndef load_image(img, resized_fac = 1):\n    img     = cv2.imread(img_path(img))\n    w, h, _ = img.shape\n    resized = cv2.resize(img, (int(h*resized_fac), int(w*resized_fac)), interpolation = cv2.INTER_AREA)\n    return resized","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport numpy as np\n\n# generation of a dictionary of (title, images)\nfigures = {'im'+str(i): load_image(row.image) for i, row in df.sample(6).iterrows()}\n# plot of the images in a figure, with 2 rows and 3 columns\nplot_figures(figures, 2, 3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The Dataset is made up of different items that can be found in a marketplace. The idea is to use embeddings to search for similarity and find similar items just using the image."},{"metadata":{},"cell_type":"markdown","source":"## Use Pre-Trained Model to Recommendation"},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow as tf\nimport keras\nfrom keras import Model\nfrom keras.preprocessing import image\nfrom keras.layers import GlobalMaxPooling2D\ntf.__version__","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# detect and init the TPU\ntpu = tf.distribute.cluster_resolver.TPUClusterResolver()\ntf.config.experimental_connect_to_cluster(tpu)\ntf.tpu.experimental.initialize_tpu_system(tpu)\n\n# instantiate a distribution strategy\ntpu_strategy = tf.distribute.experimental.TPUStrategy(tpu)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Input Shape\nimg_width, img_height, _ = 450, 600, 3 #load_image(df.iloc[0].image).shape\n\n# Pre-Trained Model\nbase_model = InceptionV3(weights='imagenet', \n                      include_top=False, \n                      input_shape = (img_width, img_height, 3))\nbase_model.trainable = False\n\n# Add Layer Embedding\nmodel = keras.Sequential([\n    base_model,\n    GlobalMaxPooling2D()\n])\n\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"it=0\ndef get_embedding(model, img_name):\n    # Reshape\n    global it\n    it=it+1\n    img = image.load_img(img_path(img_name), target_size=(img_width, img_height))\n    # img to Array\n    x   = image.img_to_array(img)\n    # Expand Dim (1, w, h)\n    x   = np.expand_dims(x, axis=0)\n    # Pre process Input\n    x   = preprocess_input(x)\n    print(it)\n    return model.predict(x).reshape(-1)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Get item Embedding"},{"metadata":{"trusted":true},"cell_type":"code","source":"emb = get_embedding(model, df.iloc[0].image)\nemb.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"img_array = load_image(df.iloc[1].image)\nplt.imshow(cv2.cvtColor(img_array, cv2.COLOR_BGR2RGB))\nprint(img_array.shape)\nprint(emb)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Get Embedding for all itens in dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n#import swifter\n\n# Parallel apply\ndf_sample      = df#.sample(10)\nmap_embeddings = df_sample['image'].apply(lambda img: get_embedding(model, img))\ndf_embs        = map_embeddings.apply(pd.Series)\n\nprint(df_embs.shape)\ndf_embs.head()\n# reduce_mem_usage(df_embs)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Compute Similarity Between Items"},{"metadata":{"trusted":true},"cell_type":"code","source":"# https://scikit-learn.org/stable/modules/generated/sklearn.metrics.pairwise_distances.html\nfrom sklearn.metrics.pairwise import pairwise_distances\n\n\n# Calcule DIstance Matrix\n# reduce_mem_usage(df_embs)\n# cosine_sim = 1-pairwise_distances(df_embs, metric='cosine')\n# cosine_sim[:4, :4]\n# reduce_mem_usage(cosine_sim )","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Recommender Similar Items"},{"metadata":{"trusted":true},"cell_type":"code","source":"indices = pd.Series(range(len(df_embs)), index=df_embs.index)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from scipy.spatial.distance import cosine\n# Function that get movie recommendations based on the cosine similarity score of movie genres\ndef get_recommender(idx, df, options, top_n = 5):\n    sim_idx    = indices[idx]\n    \n    filteredIndices = set();\n    \n    if len(options) > 0:\n        it = 0\n        for column in options:\n            if it == 0:\n                filteredIndices = set(df.index[df[column]== options[column]].tolist())\n            else:\n                filteredIndices = filteredIndices & set(df.index[df[column]== options[column]].tolist())\n            it = it + 1\n            \n        filteredIndices = list(filteredIndices)\n#         print(len(filteredIndices) )\n    else:\n        filteredIndices = list(indices.index)\n#     sim_scores =[];\n#     for i in range(len(df_embs)):\n#         sim_scores[i] = 1-cdist(df_embs[df_embs.index == sim_idx],df_embs[i], metric='cosine')\n    cosine_sim = [ 1 - cosine(df_embs.iloc[sim_idx], df_embs.iloc[i]) for i in range(len(df_embs))]\n    sim_scores = list(enumerate(cosine_sim))\n    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n    sim_scores = sim_scores[1: ]\n    \n    idx_rec = []\n    idx_sim = []\n    count_sim = 0\n    \n    for i in sim_scores:\n        if i[0] in filteredIndices:\n            idx_rec.append(i[0])\n            idx_sim.append(i[1])\n            count_sim = count_sim + 1\n            \n            if count_sim >= top_n:\n                break\n            \n    \n    idx_rec = indices.iloc[idx_rec].index\n    plt.imshow(cv2.cvtColor(load_image(df.iloc[idx].image), cv2.COLOR_BGR2RGB))\n    \n    \n    if(len(idx_rec) <= 0):\n        print('No matching item found for', options)\n        return\n    \n    plot_row = math.ceil(len(idx_sim)/3)\n    plot_col = min(3, len(idx_sim))\n        # Plot\n        #===================\n        # generation of a dictionary of (title, images)\n    figures = {'im'+str(i): load_image(row.image) for i, row in df.loc[idx_rec].iterrows()}\n        # plot of the images in a figure, with 2 rows and 3 columns\n    if len(figures):\n        plot_figures(figures, plot_row, plot_col)\n\nget_recommender(2992, df, {}, top_n = 6)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"base_color_filter = df['baseColour']=='Green'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(df_embs)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.iloc[19572].gender ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Idx Item to Recommender\nidx_ref = 7831\n\n# Recommendations\nget_recommender(idx_ref, df, { }, top_n = 6)\n# get_recommender(idx_ref, df, { \"gender\":df.iloc[idx_ref].gender }, top_n = 6)\n# get_recommender(idx_ref, df, { \"articleType\":df.iloc[idx_ref].articleType }, top_n = 6)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[df.index == 22]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[df.subCategory == 'Shoe'][df.baseColour == 'Black']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Search for items similar to the reference to recommend. Apparently it's working!**"},{"metadata":{"trusted":true},"cell_type":"code","source":"idx_ref = 8921\n\n# Recommendations\nidx_rec, idx_sim = get_recommender(idx_ref, df, {}, top_n = 6)\n\n# Plot\n#===================\nplt.imshow(cv2.cvtColor(load_image(df.iloc[idx_ref].image), cv2.COLOR_BGR2RGB))\n\n# generation of a dictionary of (title, images)\nfigures = {'im'+str(i): load_image(row.image) for i, row in df.loc[idx_rec].iterrows()}\n# plot of the images in a figure, with 2 rows and 3 columns\nplot_figures(figures, 2, 3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"idx_ref = 987\n\n# Recommendations\nidx_rec, idx_sim = get_recommender(idx_ref, df, {}, top_n = 6)\n\n# Plot\n#===================\nplt.imshow(cv2.cvtColor(load_image(df.iloc[idx_ref].image), cv2.COLOR_BGR2RGB))\n\n# generation of a dictionary of (title, images)\nfigures = {'im'+str(i): load_image(row.image) for i, row in df.loc[idx_rec].iterrows()}\n# plot of the images in a figure, with 2 rows and 3 columns\nplot_figures(figures, 2, 3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"idx_ref = 3524\n\n# Recommendations\nidx_rec, idx_sim = get_recommender(idx_ref, df, {}, top_n = 6)\n\n# Plot\n#===================\nplt.imshow(cv2.cvtColor(load_image(df.iloc[idx_ref].image), cv2.COLOR_BGR2RGB))\n\n# generation of a dictionary of (title, images)\nfigures = {'im'+str(i): load_image(row.image) for i, row in df.loc[idx_rec].iterrows()}\n# plot of the images in a figure, with 2 rows and 3 columns\nplot_figures(figures, 2, 3)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4"}},"nbformat":4,"nbformat_minor":4}